{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Pre and Post Simulation Tasks on Energy Exemplar Cloud. \n",
    "Pre and Post Simulation tasks enables you to run custom logic before or after a simulation on cloud. Python scripts are supported by default, but you also have abilty to run native code compiled for Linux and x64 architecture. All scripts or artifacts needed for your tasks need to be uploaded into Energy Exemplar Datahub, which will be accessible during run on the cloud. Datahub provides a seamless storage mechansism and offers versioning and account control capability. Multiple tasks can be configured to run before or after a run. Task output can be manually uploaded to Datahub, or you can retrieve data via CLI manually. \n",
    "\n",
    "### Covered in this Example\n",
    "1. Python libraries, environment variables and SDK setup\n",
    "2. Setting SDK/CLI Environment\n",
    "3. Authentication (SSO)\n",
    "4. Authentication (Service Principal)\n",
    "5. Configure Datahub Sync directory\n",
    "6. Sync local content with Datahub\n",
    "7. List Datahub content\n",
    "8. Configure Simulation and Tasks\n",
    "9. Enqueue Simulation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate the Python SDK client, Setup variables. <a class=\"anchor\" id=\"environment-setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import utilities\n",
    "from pathlib import Path\n",
    "from eecloud.cloudsdk import CloudSDK, SDKBase\n",
    "from eecloud.models import *\n",
    "\n",
    "repo_name = \"JupyterSamples\"\n",
    "root_path = os.environ.get(\"HOME\")\n",
    "jupyter_user = os.environ.get(\"JUPYTERHUB_USER\")\n",
    "project_root = local_path = os.path.join(root_path, repo_name, \"PreAndPostTasks\")\n",
    "\n",
    "local_path = os.path.join(project_root, \"Scripts\") \n",
    "datahub_path = f\"{repo_name}/{jupyter_user}\"\n",
    "simulation_body = os.path.join(local_path, \"simulation_body.json\")\n",
    "\n",
    "solution_download_directory = os.path.join(project_root, \"Downloads\")\n",
    "cli_path = os.environ.get(\"cloud_cli_path\")\n",
    "environment: str = \"PreProd\"\n",
    "\n",
    "if environment is None:\n",
    "    raise Exception(\"environment value must be configured\")\n",
    "\n",
    "# Setting an environment variable named \"cloud_cli_path\" with full path to CLI prevented need to configure SDK manually\n",
    "pxc = CloudSDK()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    environment_response = pxc.environment.set_user_environment(environment, print_message=False)\n",
    "    environment_data = pxc.environment.get_final_response(environment_response)\n",
    "    print(f\"{environment_data.EventData.Environment} selected, please authenticate\")\n",
    "except Exception as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Login to PLEXOS Cloud using SSO - This will only work locally not on Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXAMPLE for Local Notebook Use.\n",
    "#try:\n",
    "#    login_response = pxc.auth.login(print_message=False)\n",
    "#    login_data = pxc.auth.get_final_response(login_response)\n",
    "#    print(f\"{login_data.EventData.UserName} ({login_data.EventData.TenantName}) logged into {login_data.EventData.Environment}\")\n",
    "#except Exception as ex:\n",
    "#    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Login to PLEXOS Cloud using Client credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ee_tenant_id = 'TENANT_ID'\n",
    "    ee_client_id = 'CLIENT_ID'\n",
    "    ee_client_secret = 'SECRET'\n",
    "    \n",
    "    command_responses = pxc.auth.login_client_credentials(tenant_id=ee_tenant_id, client_id=ee_client_id, client_secret=ee_client_secret, use_client_credentials=True, print_message=False)\n",
    "    last_command_response: CommandResponse[Contracts_LoginResponse] = pxc.auth.get_final_response(command_responses)\n",
    "    if last_command_response is not None and last_command_response.Status == \"Success\":\n",
    "        data: Contracts_LoginResponse = last_command_response.EventData\n",
    "        print(f\"{data.TenantName} logged into {data.Environment}\")\n",
    "    else:\n",
    "        print(f\"Failure to login: {last_command_response.Message}\")\n",
    "except Exception as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup Datahub to local folder sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(f\"Attempting to map local path: {local_path} to {datahub_path} on Datahub\")\n",
    "    command_responses = pxc.datahub.map_folder(local_path, datahub_path, print_message=False)\n",
    "    last_command_response: CommandResponse[Contracts_DatahubMapResponse] = pxc.datahub.get_final_response(command_responses)\n",
    "    if last_command_response is not None and last_command_response.Status == \"Success\":\n",
    "        data: Contracts_DatahubMapResponse = last_command_response.EventData\n",
    "        print(f\"{data.LocalPath} mapped to {data.RemotePath} on Datahub\")\n",
    "    elif last_command_response is not None:\n",
    "        print(last_command_response.Message)\n",
    "except Exception as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sync data in between mapped local folder and Datahub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    command_responses = pxc.datahub.sync(local_path_to_sync=local_path, verify_downloads=False, replace_local_files_on_conflict=True, print_message=False)\n",
    "    last_command_response: CommandResponse[Contracts_DatahubCommandResponse] = pxc.datahub.get_final_response(command_responses)\n",
    "    if last_command_response is not None and last_command_response.Status == \"Success\":\n",
    "        data: Contracts_DatahubCommandResponse = last_command_response.EventData\n",
    "    \n",
    "        if len(data.DatahubResourceResults) == 0:\n",
    "            print(\"No changes found\")\n",
    "    \n",
    "        for item in data.DatahubResourceResults:\n",
    "            if item.Success == True:\n",
    "                print(item.RelativeFilePath)\n",
    "            elif \"Skipping upload\" in item.FailureReason:\n",
    "                print(f\"Skipped: {item.RelativeFilePath} - Identical\")\n",
    "            else:\n",
    "                print(f\"Failed {item.RelativeFilePath} - {item.FailureReason}\")\n",
    "    else:\n",
    "        print(\"Failed to sync data between local and remote filesystems\")\n",
    "except Exception as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List Datahub files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    search_response: list[CommandResponse[Contracts_DatahubSearchResponse]] = pxc.datahub.search([f\"{datahub_path}/**\"], print_message=False)\n",
    "    search_data: Contracts_DatahubSearchResponse = pxc.datahub.get_final_response(search_response)\n",
    "    \n",
    "    for item in search_data.EventData.DatahubSearchResults:\n",
    "        if item.IsDeleted == False:\n",
    "            print(f\"{item.RelativePath} - Total Versions: {len(item.Versions)} : Latest Version: {item.LatestServerVersion}\")\n",
    "except Exception as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Tasks in Simulation Payload <a class=\"anchor\" id=\"define-tasks\"></a>\n",
    "\n",
    "Manually update the [simulation_body.json](Scripts/simulation_body.json) located in the Scripts directory. The following must be updated\n",
    "- StudyId\n",
    "- ChangesetId\n",
    "- Models\n",
    "- SimulationData\n",
    "- SimulationEngine\n",
    "- The tasks under SimulationTasks must be updated to include your Datahub path names. Documentation here: [Task Documentation](https://portal.energyexemplar.com/unified-help/plexos-cloud/#t=Simulations%2FPre-_and_Post-Simulation_Tasks.htm&rhsearch=pre%20and%20post&ux=search) \n",
    "  - TaskType: - Pre or Post\n",
    "  - Files: Datahub Path and Version\n",
    "  - Arguments: If python script needs to be executed, the arguments must contain \"python3 yourscript.py\"\n",
    "\n",
    "*** If new scripts are added, the sync process must be run again. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```json\n",
    "...\n",
    "{\n",
    "    \"Name\": \"TASK NAME\",\n",
    "    \"TaskType\": \"Pre\",\n",
    "    \"Files\": [\n",
    "        {\n",
    "            \"Path\": \"JupyterSamples/<user.name>/query_write_memberships.py\",\n",
    "            \"Version\": null\n",
    "        },\n",
    "        {\n",
    "            \"Path\": \"JupyterSamples/<user.name>/requirements.txt\",\n",
    "            \"Version\": 1\n",
    "        }\n",
    "    ],\n",
    "    \"Arguments\": \"python3 query_write_memberships.py\",\n",
    "    \"ContinueOnError\": true,\n",
    "    \"ExecutionOrder\": 1\n",
    "}\n",
    "...\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enqueue Simulation, Wait for Completion. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    enqueue_response = pxc.simulation.enqueue_simulation(simulation_body, print_message=False)\n",
    "    enqueue_data : Contracts_EnqueueSimulationResponse = pxc.simulation.get_final_response(enqueue_response)\n",
    "    simulation = enqueue_data.EventData.SimulationStarted[0]\n",
    "\n",
    "    simulation_id = simulation.Id.Value\n",
    "    execution_id = simulation.ExecutionId.Value\n",
    "\n",
    "    print(f\"Simulation: {simulation_id} enqueued\")\n",
    "\n",
    "    utilities.wait_simulation_finish(pxc, simulation_id)\n",
    "    simulation_result = utilities.get_simulation(pxc, simulation_id=simulation_id)\n",
    "\n",
    "    #optionally if multiple simulations were enqueued we can wait for all executions to finish \n",
    "    #execution_result = utilities.get_executions(pxc, execution_id=simulation_result.ExecutionId.Value)\n",
    "    #execution_result = utilities.wait_execution_finish(pxc, execution_id=simulation_result.ExecutionId.Value)\n",
    "\n",
    "    if simulation_result.Status in ['CompletedSuccess']:\n",
    "        solution_id = simulation_result.ModelIdentifiers[0].Id\n",
    "        print(f\"Simulation complete. {simulation_result.Status} Downloading artifacts for solution: {solution_id}\")  \n",
    "        Path(solution_download_directory).mkdir(parents=True, exist_ok=True)\n",
    "        utilities.download_solution_data(pxc, solution_id , solution_download_directory)\n",
    "        print(f\"Solution data downloaded to {solution_download_directory}\")\n",
    "    else:\n",
    "        print(f\"Simulation finished: {simulation_result.Status} - Possible failure\")\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
